



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Tugas Data Mining">
      
      
        <link rel="canonical" href="https://github.com/RizkaRamadhani/tree/">
      
      
        <meta name="author" content="RizkaRamadhani">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Decision Tree - Data Mining</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#konsep-pohon-keputusan" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://github.com/RizkaRamadhani" title="Data Mining" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Data Mining
            </span>
            <span class="md-header-nav__topic">
              Decision Tree
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/170441100081rizkaramadhani/DataMining" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    DataMining
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="K-Mean Clustering dan KNN" class="md-tabs__link md-tabs__link--active">
        K-Mean Clustering dan KNN
      </a>
    
  </li>

      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://github.com/RizkaRamadhani" title="Data Mining" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Data Mining
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/170441100081rizkaramadhani/DataMining" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    DataMining
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="K-Mean Clustering dan KNN" class="md-nav__link">
      K-Mean Clustering dan KNN
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Decision Tree
      </label>
    
    <a href="./" title="Decision Tree" class="md-nav__link md-nav__link--active">
      Decision Tree
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#konsep-pohon-keputusan" title="Konsep Pohon Keputusan" class="md-nav__link">
    Konsep Pohon Keputusan
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pengertian-pohon-keputusan" title="Pengertian Pohon Keputusan" class="md-nav__link">
    Pengertian Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algoritma-pohon-keputusan" title="Algoritma Pohon Keputusan" class="md-nav__link">
    Algoritma Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manfaat-pohon-keputusan" title="Manfaat Pohon Keputusan" class="md-nav__link">
    Manfaat Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kelebihan-pohon-keputusan" title="Kelebihan  Pohon Keputusan" class="md-nav__link">
    Kelebihan  Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kekurangan-pohon-keputusan" title="Kekurangan Pohon Keputusan" class="md-nav__link">
    Kekurangan Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-dalam-kontruksi-pohon-keputusan" title="Langkah-Langkah dalam kontruksi pohon keputusan" class="md-nav__link">
    Langkah-Langkah dalam kontruksi pohon keputusan
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#entropi" title="Entropi" class="md-nav__link">
    Entropi
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gain-ratio" title="Gain Ratio" class="md-nav__link">
    Gain Ratio
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementasi" title="IMPLEMENTASI" class="md-nav__link">
    IMPLEMENTASI
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#konsep-pohon-keputusan" title="Konsep Pohon Keputusan" class="md-nav__link">
    Konsep Pohon Keputusan
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pengertian-pohon-keputusan" title="Pengertian Pohon Keputusan" class="md-nav__link">
    Pengertian Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#algoritma-pohon-keputusan" title="Algoritma Pohon Keputusan" class="md-nav__link">
    Algoritma Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#manfaat-pohon-keputusan" title="Manfaat Pohon Keputusan" class="md-nav__link">
    Manfaat Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kelebihan-pohon-keputusan" title="Kelebihan  Pohon Keputusan" class="md-nav__link">
    Kelebihan  Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kekurangan-pohon-keputusan" title="Kekurangan Pohon Keputusan" class="md-nav__link">
    Kekurangan Pohon Keputusan
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-dalam-kontruksi-pohon-keputusan" title="Langkah-Langkah dalam kontruksi pohon keputusan" class="md-nav__link">
    Langkah-Langkah dalam kontruksi pohon keputusan
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#entropi" title="Entropi" class="md-nav__link">
    Entropi
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gain-ratio" title="Gain Ratio" class="md-nav__link">
    Gain Ratio
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#implementasi" title="IMPLEMENTASI" class="md-nav__link">
    IMPLEMENTASI
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                  <h1>Decision Tree</h1>
                
                <h2 id="konsep-pohon-keputusan">Konsep Pohon Keputusan<a class="headerlink" href="#konsep-pohon-keputusan" title="Permanent link">&para;</a></h2>
<h3 id="pengertian-pohon-keputusan"><strong>Pengertian Pohon Keputusan</strong><a class="headerlink" href="#pengertian-pohon-keputusan" title="Permanent link">&para;</a></h3>
<p>Pohon yang dalam analisis pemecahan masalah pengambilan keputusan  adalah pemetaan mengenai alternatif-alternatif pemecahan masalah yang  dapat diambil dari masalah tersebut. Pohon tersebut juga memperlihatkan  faktor-faktor kemungkinan/probablitas yang akan mempengaruhi  alternatif-alternatif keputusan tersebut, disertai dengan estimasi hasil  akhir yang akan didapat bila kita mengambil alternatif keputusan  tersebut.</p>
<p><img alt="Material for Mkdocs" src="../assets/images/1.decision-tree.gif" /></p>
<h3 id="algoritma-pohon-keputusan"><strong>Algoritma Pohon Keputusan</strong><a class="headerlink" href="#algoritma-pohon-keputusan" title="Permanent link">&para;</a></h3>
<p>Pohon keputusan adalah model prediksi menggunakan struktur pohon atau  struktur berhirarki. </p>
<p>Model  pohon  keputusan  dibuat  menyerupai  bentuk  pohon,  dimana pada umumnya  sebuah  pohon terdapat  akar  (root),  cabang  dan  daun  (leaf). Pada pohon keputusan juga terdiri  dari tiga bagian sebagai berikut : </p>
<p>a.Root node</p>
<p>Root node atau node akar merupakan node yang terletak paling atas dari suatu pohon. </p>
<p>b.Internal node </p>
<p>Internal  node ini  merupakan node percabangan,  dimana  pada  node  ini hanya terdapat satu input dan mempunyai minimal dua output.</p>
<p>c.Leaf node</p>
<p>Node ini  merupakan node  akhir,  hanya  memiliki  satu  input,  dan  tidak memiliki  output. Pada  pohon  keputusan  setiap leaf  node menandai  label kelas.</p>
<p>Contoh dari pohon keputusan dapat dilihat di  Gambar berikut ini.</p>
<p><img alt="Material for Mkdocs" src="../assets/images/Algoritma pohon keputusan.PNG" /></p>
<p>Lambang bulat pada pohon keputusan melambangkan node akar (root node) dan  juga  node  cabang  (internal  node). Namun  node  akar  selalu  terletak  paling atas  tanpa memiliki  input,  sedangkan  node  cabang  mempunyai  input. Lambang kotak melambangkan node daun (leaf node). Setiap node daun berisi nilai atribut dari node cabang atau node akarnya. </p>
<h3 id="manfaat-pohon-keputusan"><strong>Manfaat Pohon Keputusan</strong><a class="headerlink" href="#manfaat-pohon-keputusan" title="Permanent link">&para;</a></h3>
<p>Manfaat utama dari penggunaan pohon keputusan adalah kemampuannya untuk mem-<em>break down</em>  proses pengambilan keputusan yang kompleks menjadi lebih simpel sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Pohon Keputusan juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Pohon keputusan memadukan antara eksplorasi data dan pemodelan, sehingga  sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain. Sering terjadi tawar menawar antara keakuratan model dengan transparansi model. Dalam beberapa aplikasi, akurasi dari  sebuah klasifikasi atau prediksi adalah satu-satunya hal yang ditonjolkan, misalnya sebuah perusahaan <em>direct mail</em> membuat sebuah model yang akurat untukmemprediksi anggota mana yang berpotensi untuk merespon permintaan, tanpa memperhatikan bagaimana atau mengapa model tersebut bekerja.</p>
<h3 id="kelebihan-pohon-keputusan"><strong>Kelebihan  Pohon Keputusan</strong><a class="headerlink" href="#kelebihan-pohon-keputusan" title="Permanent link">&para;</a></h3>
<p>Kelebihan metode pohon keputusan adalah:</p>
<ul>
<li>
<p>Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik.</p>
</li>
<li>
<p>Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena  ketika menggunakan metode pohon keputusan maka sample diuji hanya  berdasarkan kriteria atau kelas tertentu.</p>
</li>
<li>
<p>Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur  yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang  lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini  meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika  menggunakan metode penghitungan satu tahap yang lebih konvensional</p>
</li>
<li>
<p>Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya  sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan  baik itu distribusi dimensi tinggi ataupun parameter tertentu dari  distribusi kelas tersebut. Metode pohon keputusan dapat menghindari  munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya  lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas  keputusan yang dihasilkan.</p>
</li>
</ul>
<h3 id="kekurangan-pohon-keputusan"><strong>Kekurangan Pohon Keputusan</strong><a class="headerlink" href="#kekurangan-pohon-keputusan" title="Permanent link">&para;</a></h3>
<ul>
<li>Terjadi overlap terutama ketika kelas-kelas dan criteria yang  digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan  meningkatnya waktu pengambilan keputusan dan jumlah memori yang  diperlukan.</li>
<li>Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar.</li>
<li>Kesulitan dalam mendesain pohon keputusan yang optimal.</li>
<li>Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.</li>
</ul>
<h3 id="langkah-langkah-dalam-kontruksi-pohon-keputusan"><strong>Langkah-Langkah dalam kontruksi pohon keputusan</strong><a class="headerlink" href="#langkah-langkah-dalam-kontruksi-pohon-keputusan" title="Permanent link">&para;</a></h3>
<p>Adapun langkah-langkah dalam konstruksi pohon keputusan adalah sebagai berikut : </p>
<p>Langkah 1: Pohon  dimulai  dengan  sebuah  simpul  yang  mereperesentasikan sampel data pelatihan yaitu dengan membuat simpul akar.</p>
<p>Langkah 2 :  Jika semua sampel berada dalam kelas yang sama, maka simpul ini  menjadi  daun  dan  dilabeli  menjadi  kelas.  Jika  tidak, gain  ratio akan  digunakan  untuk  memilih  atribut  split,  yaitu  atribut  yang terbaik   dalam   memisahkan   data   sampel   menjadi   kelas-kelas individu.</p>
<p>Langkah 3 :  Cabang  akan  dibuat  untuk  setiap  nilai  pada  atribut  dan  data sampel akan dipartisi lagi.</p>
<p>Langkah 4 : Algoritma menggunakan  proses  rekursif  untuk  membentuk pohon  keputusan  pada  setiap  data  partisi.  Jika  sebuah  atribut sudah  digunakan  disebuah  simpul,  maka atribut tidak akan digunakan lagi di simpul anak-anaknya.</p>
<p>Langkah 5 : Proses akan berhenti jika dicapai kondisi seperti berikut :</p>
<p>-Semua sampel pada simpul berada di dalam satu kelas </p>
<p>-Tidak   ada   atribut   lainnya   yang   dapat   digunakan   untuk mempartisi  sampel  lebih  lanjut. Dalam  hal  ini  akan  diterapkan suara terbanyak. Ini berarti mengubah sebuah simpul menjadi daun dan melabelinya dengan kelas pada suara terbanyak. </p>
<ul>
<li>
<h4 id="entropi"><strong>Entropi</strong><a class="headerlink" href="#entropi" title="Permanent link">&para;</a></h4>
</li>
</ul>
<p>Entropi merupakan pengukuran ketidakpastian rata-rata  kumpulan  data  ketika  kita  tidak  tahu  hasil  dari  sumber  informasi.  Itu berarti bahwa seberapa banyak pengukuran informasi  yang kita tidak  punya.  Ini juga menunjukkan jumlah rata-rata informasi yang kami akan menerima dari hasil sumber informasi. Untuk mendapatkan nilai gain ratiodalam pembentukan pohon keputusan,  perlu  menghitung  dulu  nilai  informasi  dalam  satuan  bits  dari  suatu kumpulan objek.</p>
<p>Bentuk perhitungan untuk entropi adalah sebagai berikut :</p>
<p><img alt="Material for Mkdocs" src="../assets/images/Rumus entropi 2.PNG" /></p>
<p>​       Entropi split yang membagi X dengan n record menjadi himpunan-himpunan X1 dengan n1 baris dan       X2 dengan n2 baris adalah :</p>
<p><img alt="Material for Mkdocs" src="../assets/images/splisit 2.PNG" /></p>
<p>​       Besar nilai Entropy (X) menunjukkan bahwa X adalah atribut yang lebih acak. Di  sisi  lain,  atribut  yang          lebih  kecil dari  nilai Entropy(X) menyiratkan  atribut  ini sedikit lebih acak yang signifikan untuk data mining. Nilai entropi mencapai nilai minimum 0, ketika semua pj lain = 0 atau berada pada kelas yang sama. Nilainya mencapai maksimum log2k, ketika semua nilai pj adalah sama dengan 1/k.</p>
<ul>
<li>
<h4 id="gain-ratio"><strong>Gain Ratio</strong><a class="headerlink" href="#gain-ratio" title="Permanent link">&para;</a></h4>
</li>
</ul>
<p><img alt="Material for Mkdocs" src="../assets/images/gen ratio.PNG" /></p>
<p>Dimana gain(a) adalah information gaindari atribut auntuk himpunan sampel X dan split info(a) menyatakan entropi atau informasi potensial yang didapat pada pembagian X menjadi n  sub himpunan  berdasarkan  telaahan  pada  atribut a. Sedangkan gain (a) didefinisikan sebagai berikut :</p>
<p><img alt="Material for Mkdocs" src="../assets/images/gain a.PNG" /></p>
<p>Untuk rumus split info(a) adalah sebagai berikut :</p>
<p><img alt="Material for Mkdocs" src="../assets/images/split a.PNG" /></p>
<p>dimana Xi menyatakan sub himpunan ke -I pada sampel X. Dengan  kata  lain  rumus  untuk  menghitung  nilai  gain  ratio  untuk  dipilih sebagai atribut dari simpul yang ada sebagai berikut ini </p>
<p><img alt="Material for Mkdocs" src="../assets/images/gen ration a.PNG" /></p>
<h3 id="implementasi"><strong>IMPLEMENTASI</strong><a class="headerlink" href="#implementasi" title="Permanent link">&para;</a></h3>
<p>Implementasi dari data pada program phython. Agar program dapat berjalan, maka diperlukan beberapa library dari phyton untuk mendukung jalannya program tersebut. Antara lain pandas dan scikit-learn, kedua library tersebut di install melalui command promt. Dengan cara :</p>
<pre class="codehilite"><code>pip install pandas</code></pre>

<pre class="codehilite"><code>pip install scikit-learn</code></pre>

<p>Setelah memiliki library tersebut pada phyton, selanjutnya adalah tuliskan program</p>
<p><strong>[SOURCE CODE]</strong></p>
<pre class="codehilite"><code># Run this program on your local python
# interpreter, provided you have installed
# the required libraries.

# Importing the required packages
import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

# Function importing Dataset
def importdata():
    balance_data = pd.read_csv("iris.csv",sep= ',', header = 1)

    # Printing the dataset shape
    print ("Dataset Lenght: ", len(balance_data))
    print ("Dataset Shape: ", balance_data.shape)

    # Printing the dataset observations
    print('dataset :')
    print (balance_data.head())
    return balance_data

# Function to split the dataset
def splitdataset(balance_data):

    # Seperating the target variable
    X = balance_data.values[:, 1:5]
    Y = balance_data.values[:, 0]

    # Spliting the dataset into train and test
    X_train, X_test, y_train, y_test = train_test_split(
    X, Y, test_size = 0.3, random_state = 100)

    return X, Y, X_train, X_test, y_train, y_test

# Function to perform training with giniIndex.
def train_using_gini(X_train, X_test, y_train):

    # Creating the classifier object
    clf_gini = DecisionTreeClassifier(criterion = "gini",
            random_state = 100,max_depth=3, min_samples_leaf=5)

    # Performing training
    clf_gini.fit(X_train, y_train)
    return clf_gini

# Function to perform training with entropy.
def tarin_using_entropy(X_train, X_test, y_train):

    # Decision tree with entropy
    clf_entropy = DecisionTreeClassifier(
            criterion = "entropy", random_state = 100,
            max_depth = 3, min_samples_leaf = 5)

    # Performing training
    clf_entropy.fit(X_train, y_train)
    return clf_entropy


# Function to make predictions
def prediction(X_test, clf_object):

    # Predicton on test with giniIndex
    y_pred = clf_object.predict(X_test)
    print("Predicted values:")
    print(y_pred)
    return y_pred

# Function to calculate accuracy
def cal_accuracy(y_test, y_pred):

    print("Confusion Matrix: ",
        confusion_matrix(y_test, y_pred))

    print ("Accuracy : ",
    accuracy_score(y_test,y_pred)*100)

    print("Report : ",
    classification_report(y_test, y_pred))

# Driver code
def main():

    # Building Phase
    data = importdata()
    X, Y, X_train, X_test, y_train, y_test = splitdataset(data)
    clf_gini = train_using_gini(X_train, X_test, y_train)
    clf_entropy = tarin_using_entropy(X_train, X_test, y_train)

    # Operational Phase
    print("Results Using Gini Index:")

    # Prediction using gini
    y_pred_gini = prediction(X_test, clf_gini)
    cal_accuracy(y_test, y_pred_gini)

    print("Results Using Entropy:")
    # Prediction using entropy
    y_pred_entropy = prediction(X_test, clf_entropy)
    cal_accuracy(y_test, y_pred_entropy)


# Calling main function
if __name__=="__main__":
    main()
</code></pre>

<p><strong><em>Keterangan :</em></strong></p>
<pre class="codehilite"><code># Function importing Dataset
def importdata():
    balance_data = pd.read_csv("iris.csv",sep= ',', header = 1)

    # Printing the dataset shape
    print ("Dataset Lenght: ", len(balance_data))
    print ("Dataset Shape: ", balance_data.shape)

    # Printing the dataset observations
    print('dataset :')
    print (balance_data.head())
    return balance_data</code></pre>

<p>Diatas adalah kode program untuk mengimportkan dan menampilkan data</p>
<pre class="codehilite"><code># Function to split the dataset
def splitdataset(balance_data):

    # Seperating the target variable
    X = balance_data.values[:, 1:5]
    Y = balance_data.values[:, 0]

    # Spliting the dataset into train and test
    X_train, X_test, y_train, y_test = train_test_split(
    X, Y, test_size = 0.3, random_state = 100)

    return X, Y, X_train, X_test, y_train, y_test
</code></pre>

<p>Diatas merupakan kode program untuk membagi dataset  def splitdataset</p>
<pre class="codehilite"><code># Function to perform training with giniIndex.
def train_using_gini(X_train, X_test, y_train):

    # Creating the classifier object
    clf_gini = DecisionTreeClassifier(criterion = "gini",
            random_state = 100,max_depth=3, min_samples_leaf=5)

    # Performing training
    clf_gini.fit(X_train, y_train)
    return clf_gini</code></pre>

<p>Diatas merupakan kode program untuk menentukan pohon keputusan menggunakan giniindex</p>
<pre class="codehilite"><code># Function to perform training with entropy.
def tarin_using_entropy(X_train, X_test, y_train):

    # Decision tree with entropy
    clf_entropy = DecisionTreeClassifier(
            criterion = "entropy", random_state = 100,
            max_depth = 3, min_samples_leaf = 5)

    # Performing training
    clf_entropy.fit(X_train, y_train)
    return clf_entropy</code></pre>

<p>Diatas merupakan kode program untuk menentukan pohon keputusan menggunakan entropy </p>
<pre class="codehilite"><code># Function to make predictions
def prediction(X_test, clf_object):

    # Predicton on test with giniIndex
    y_pred = clf_object.predict(X_test)
    print("Predicted values:")
    print(y_pred)
    return y_pred</code></pre>

<p>Kode program diatas merupakan kode program yang berfungsi untuk membuat prediksi pada hasil akhir</p>
<pre class="codehilite"><code># Function to calculate accuracy
def cal_accuracy(y_test, y_pred):

    print("Confusion Matrix: ",
        confusion_matrix(y_test, y_pred))

    print ("Accuracy : ",
    accuracy_score(y_test,y_pred)*100)

    print("Report : ",
    classification_report(y_test, y_pred))
</code></pre>

<p>Kode program diatas adalah kode program untuk menghitung akuransi data</p>
<pre class="codehilite"><code># Driver code
def main():

    # Building Phase
    data = importdata()
    X, Y, X_train, X_test, y_train, y_test = splitdataset(data)
    clf_gini = train_using_gini(X_train, X_test, y_train)
    clf_entropy = tarin_using_entropy(X_train, X_test, y_train)

    # Operational Phase
    print("Results Using Gini Index:")

    # Prediction using gini
    y_pred_gini = prediction(X_test, clf_gini)
    cal_accuracy(y_test, y_pred_gini)

    print("Results Using Entropy:")
    # Prediction using entropy
    y_pred_entropy = prediction(X_test, clf_entropy)
    cal_accuracy(y_test, y_pred_entropy)
</code></pre>

<p>Kode driver merupakan kode program yang berfungsi untuk mengumpulkan semua perintah yang difungsikan </p>
<pre class="codehilite"><code># Calling main function
if __name__=="__main__":
    main()</code></pre>

<p>Digunkan untuk memanggil fungsi utama dalam program tersebut</p>
<p><strong>[HASIL IMPLEMENTASI]</strong></p>
<pre class="codehilite"><code>Dataset Lenght:  149
Dataset Shape:  (149, 5)
dataset :
   Iris-setosa  5.1  3.5  1.4  0.2
0  Iris-setosa  4.9  3.0  1.4  0.2
1  Iris-setosa  4.7  3.2  1.3  0.2
2  Iris-setosa  4.6  3.1  1.5  0.2
3  Iris-setosa  5.0  3.6  1.4  0.2
4  Iris-setosa  5.4  3.9  1.7  0.4
Results Using Gini Index:
Predicted values:
['Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'
 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'
 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'
 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'
 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'
 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'
 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'
 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'
 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'
 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'
 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'
 'Iris-setosa']
Confusion Matrix:  [[16  0  0]
 [ 0  9  1]
 [ 0  2 17]]
Accuracy :  93.33333333333333
Report :                   precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        16
Iris-versicolor       0.82      0.90      0.86        10
 Iris-virginica       0.94      0.89      0.92        19

      micro avg       0.93      0.93      0.93        45
      macro avg       0.92      0.93      0.93        45
   weighted avg       0.94      0.93      0.93        45

Results Using Entropy:
Predicted values:
['Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa'
 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-setosa'
 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'
 'Iris-setosa' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'
 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'
 'Iris-virginica' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'
 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor' 'Iris-setosa'
 'Iris-versicolor' 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica'
 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'
 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'
 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'
 'Iris-setosa']
Confusion Matrix:  [[16  0  0]
 [ 0  9  1]
 [ 0  2 17]]
Accuracy :  93.33333333333333
Report :                   precision    recall  f1-score   support

    Iris-setosa       1.00      1.00      1.00        16
Iris-versicolor       0.82      0.90      0.86        10
 Iris-virginica       0.94      0.89      0.92        19

      micro avg       0.93      0.93      0.93        45
      macro avg       0.92      0.93      0.93        45
   weighted avg       0.94      0.93      0.93        45


Process finished with exit code 0
</code></pre>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href=".." title="K-Mean Clustering dan KNN" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                K-Mean Clustering dan KNN
              </span>
            </div>
          </a>
        
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016 - 2019 RizkaRamadhani
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="https://webrizka.000webhostapp.com/" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/RizkaRamadhani" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://instagram.com/RizkaRamadhani" class="md-footer-social__link fa fa-instagram"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>