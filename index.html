



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Tugas Data Mining">
      
      
        <link rel="canonical" href="https://github.com/RizkaRamadhani/">
      
      
        <meta name="author" content="RizkaRamadhani">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Data Mining</title>
      
    
    
      <link rel="stylesheet" href="assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#selamat-membaca" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://github.com/RizkaRamadhani" title="Data Mining" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Data Mining
            </span>
            <span class="md-header-nav__topic">
              K-Mean Clustering dan KNN
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/170441100081rizkaramadhani/DataMining" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    DataMining
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="." title="K-Mean Clustering dan KNN" class="md-tabs__link md-tabs__link--active">
        K-Mean Clustering dan KNN
      </a>
    
  </li>

      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://github.com/RizkaRamadhani" title="Data Mining" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Data Mining
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/170441100081rizkaramadhani/DataMining" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    DataMining
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        K-Mean Clustering dan KNN
      </label>
    
    <a href="." title="K-Mean Clustering dan KNN" class="md-nav__link md-nav__link--active">
      K-Mean Clustering dan KNN
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#k-means-clustering" title="K-Means Clustering" class="md-nav__link">
    K-Means Clustering
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apa-itu-k-means-clustering" title="Apa itu K-Means Clustering?" class="md-nav__link">
    Apa itu K-Means Clustering?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-implementasi-k-mean-clustering-pada-data-iris" title="Langkah-Langkah implementasi K-mean clustering pada data iris :" class="md-nav__link">
    Langkah-Langkah implementasi K-mean clustering pada data iris :
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knn" title="KNN" class="md-nav__link">
    KNN
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algoritma-k-nearst-neighbor" title="Algoritma K-Nearst Neighbor" class="md-nav__link">
    Algoritma K-Nearst Neighbor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-untuk-menghitung-metode-k-nearest-neighbor" title="Langkah-langkah untuk menghitung metode K-Nearest Neighbor :" class="md-nav__link">
    Langkah-langkah untuk menghitung metode K-Nearest Neighbor :
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="tree/" title="Decision Tree" class="md-nav__link">
      Decision Tree
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#k-means-clustering" title="K-Means Clustering" class="md-nav__link">
    K-Means Clustering
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#apa-itu-k-means-clustering" title="Apa itu K-Means Clustering?" class="md-nav__link">
    Apa itu K-Means Clustering?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-implementasi-k-mean-clustering-pada-data-iris" title="Langkah-Langkah implementasi K-mean clustering pada data iris :" class="md-nav__link">
    Langkah-Langkah implementasi K-mean clustering pada data iris :
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#knn" title="KNN" class="md-nav__link">
    KNN
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#algoritma-k-nearst-neighbor" title="Algoritma K-Nearst Neighbor" class="md-nav__link">
    Algoritma K-Nearst Neighbor
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#langkah-langkah-untuk-menghitung-metode-k-nearest-neighbor" title="Langkah-langkah untuk menghitung metode K-Nearest Neighbor :" class="md-nav__link">
    Langkah-langkah untuk menghitung metode K-Nearest Neighbor :
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="selamat-membaca">Selamat membaca. . .<a class="headerlink" href="#selamat-membaca" title="Permanent link">&para;</a></h1>
<h2 id="k-means-clustering"><strong>K-Means Clustering</strong><a class="headerlink" href="#k-means-clustering" title="Permanent link">&para;</a></h2>
<h3 id="apa-itu-k-means-clustering">Apa itu K-Means Clustering?<a class="headerlink" href="#apa-itu-k-means-clustering" title="Permanent link">&para;</a></h3>
<p><strong>K-Means Clustering</strong> adalah proses untuk mengelompokan data ke dalam beberapa <em>cluster</em> atau kelompok sehingga data dalam satu <em>cluster</em> memiliki tingkat kemiripan yang maksimum dan data antar <em>cluster</em> memiliki kemiripan yang minimum.</p>
<p><em>Clustering</em> juga dikenal sebagai data segmentasi karena <em>clustering</em> mempartisi banyak data set ke dalam banyak <em>group</em> berdasarkan kesamaannya. </p>
<p><img alt="Material for MkDocs" src="assets/images/cluster.png" /></p>
<p>Terdapat dua jenis data clustering yang sering dipergunakan dalam proses pengelompokan data yaitu <strong>Hierarchical</strong> dan <strong>Non-Hierarchical</strong>, dan <strong>K-Means</strong> merupakan salah satu metode data clustering non-hierarchical atau <strong>Partitional Clustering.</strong></p>
<p><img alt="Material for MkDocs" src="assets/images/1.jpg" /></p>
<p>Metode <strong>K-Means Clustering</strong> berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain.</p>
<p><img alt="Material for MkDocs" src="assets/images/2.jpg" /></p>
<p><strong>Langkah-Langkah K-mean clustering :</strong></p>
<ol>
<li>
<p>Menentukan secara acak K titik data sebagai pusatcluster yang disebut centroid. </p>
</li>
<li>
<p>Menghitung  jarak ke masing-masing pusat cluster(centroid). </p>
</li>
<li>
<p>Kemudian menghitung rata-rata dari anggota cluster. </p>
</li>
<li>
<p>Ulangai langkah 2 dan 3 sampai tidak ada  dari anggota setiap cluster berubah tempat kelompoknya. Dan dikarenakan dalam contoh ini menghasilkan anggota cluster yang tidak berubah tempat kelompoknya maka tidak ada pengulangan untuk langkah 2 dan 3.</p>
</li>
</ol>
<h3 id="langkah-langkah-implementasi-k-mean-clustering-pada-data-iris"><strong>Langkah-Langkah implementasi K-mean clustering pada data iris :</strong><a class="headerlink" href="#langkah-langkah-implementasi-k-mean-clustering-pada-data-iris" title="Permanent link">&para;</a></h3>
<p>1.Menentukan secara acak K titik data sebagai pusat cluster yang disebut centroid. </p>
<p><img alt="Material for MkDocs" src="assets/images/1.K-means langkah 1.png" /></p>
<p>​         Disini saya menggunakan 3 centroid, yakni individu 2,3 dan 4.</p>
<p><img alt="Material for MkDocs" src="assets/images/2.Gambar 2 k-means.png" /></p>
<p>2.Menghitung  jarak ke masing-masing pusat cluster (centroid).
Penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut:</p>
<pre class="codehilite"><code>= SQRT((Ki - Xi)^2+ (Kj – Xj)^2+.......+(Kn– Xn)^2)</code></pre>

<p>Keterangan:</p>
<p>K= Cluster</p>
<p>X= Objek</p>
<p>Selanjutnya masukkan anggota centroid tertentu yang memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip dengan pusat cluster (centroid). Lalu tandai masing-masing yang masuk ke cluster tertentu seperti dalam tabel berikut:</p>
<p><img alt="Material for mkDocs" src="assets/images/4.K-means.png" /></p>
<p>Sehingga, Kita dapatkan tiga cluster  dengan anggotanya pada individu: {1,2}, {4,5,6,} dan {3,7}</p>
<p>3.Kemudian menghitung  rata-rata dari anggota cluster. Penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut:</p>
<pre class="codehilite"><code>=1/n*SUM( Xi + Xj+........+ Xn)</code></pre>

<p>​   Keterangan:</p>
<p>​   n = Jumlah anggota cluster</p>
<p>​   X = Anggota cluster</p>
<p>Sehingga didapatkan tabel rata-rata sebagai berikut:</p>
<p><img alt="Matrial for MkDocs" src="assets/images/5.K-means.png" /></p>
<p>Selanjutnya hasil perhitungan rata-rata tersebut dipergunakan untuk menghitung centroid baru, dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut:</p>
<pre class="codehilite"><code>= SQRT((x ̅i - Xi)^2+ (x ̅j – Xj)^2+.......+(x ̅n– Xn)^2)</code></pre>

<p><img alt="Material for Mkdocs" src="assets/images/6.k-means.PNG" /></p>
<p>Selanjutnya masukkan anggota centroid tertentu yang  memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip. Lalu tandai masing-masing yang masuk ke cluster tertentu seperti dalam tabel berikut:</p>
<p><img alt="Material for Mkdocs" src="assets/images/7.k-means.png" /></p>
<p>Sehingga, Kita dapatkan tiga cluster  dengan anggotanya pada individu: {1,2}, {4,5,6,} dan {3,7}</p>
<p>4.Ulangi langkah 2 dan 3 sampai tidak ada  dari anggota setiap cluster berubah tempat kelompoknya. Dan dikarenakan dalam contoh ini mengahasilkan anggota cluster yang tidak berubah tempat kelompoknya maka tidak ada pengulangan untuk langkah 2 dan 3.</p>
<p><strong>MENENTUKAN JUMLAH CLUSTER</strong></p>
<p><img alt="Material for MkDocs" src="assets/images/8.Rumus.PNG" /></p>
<p>Implementasi pada Microsoft Excel sebagai berikut:</p>
<p><img alt="Material for MkDocs" src="assets/images/9.k-means.PNG" /></p>
<p><strong>MENGHITUNG SHILHOUTTE</strong></p>
<p>1.Hitung rata-rata jarak objek dengan semua objek lain yang berada di dalam satu cluster dengan persamaan :</p>
<p><img alt="Material for MkDocs" src="assets/images/10.K-means.jpg" /></p>
<p>Dengan penyelesaian menggunakan Ms.Excel, rumusnya adalah sebagai berikut :</p>
<p><img alt="Material for MkDocs" src="assets/images/10.k-means.PNG" /></p>
<p>Keterangan:</p>
<p>X = Objek</p>
<p>2.Hitung rata-rata jarak objek dengan semua objek lain yang berada pada cluster lain, dengan persamaan :</p>
<p><img alt="Material for MkDocs" src="assets/images/11.k-means.PNG" /></p>
<p>Penyelesaian menghitung jarak menggunakan Microsoft Excel dengan rumus sebagai berikut:</p>
<p>Keterangan:</p>
<p>​       K = Anggota Clust  </p>
<p>​       X = Objek</p>
<p>Selanjutnya menghitung rata-rata jarak menggunakan Microsoft Excel dengan rumus sebagai berikut:</p>
<p>=1/n*SUM( Di + Dj+........+ Dn)</p>
<p>Keterangan:</p>
<p>D = Jarak</p>
<p>n = Banyaknya jarak</p>
<p>Setelah nilai untuk mendapat nilai bi  maka cari nilai rata-rata antar cluster yang paling minimum </p>
<p>Hitung nilai silhouette coefficient, </p>
<p>dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut:</p>
<pre class="codehilite"><code>Si = 1- (ai /bi)</code></pre>

<p><strong>HASIL IMPLEMENTASI PADA EXCEL</strong></p>
<p>1.Shilhoutte Cluster 1 </p>
<p><img alt="Material for Mkdocs" src="assets/images/Sh 1.PNG" /></p>
<p>Hasil nilai silhouette coefficient adalah <strong>mendekati 1 maka pengelompokan data didalam cluster 1 bersifat baik.</strong></p>
<p>2.Shilhoutte Cluster 2</p>
<p><img alt="Material for Mkdocs" src="assets/images/Sh 2.PNG" /></p>
<p>Hasil nilai silhouette coefficient <strong>adalah mendekati -1 maka pengelompokan data
didalam cluster 1 bersifat kurang baik.</strong></p>
<p>3.Shilhoutte Cluster 3</p>
<p><img alt="Material for Mkdocs" src="assets/images/sh 3.PNG" /></p>
<p>Hasil nilai silhouette coefficient adalah <strong>mendekati -1 maka pengelompokan data didalam cluster 1 bersifat kurang baik.</strong></p>
<h2 id="knn"><strong>KNN</strong><a class="headerlink" href="#knn" title="Permanent link">&para;</a></h2>
<h3 id="algoritma-k-nearst-neighbor"><strong>Algoritma K-Nearst Neighbor</strong><a class="headerlink" href="#algoritma-k-nearst-neighbor" title="Permanent link">&para;</a></h3>
<p>​            Algoritma <em>k-nearest neighbor</em> (KNN) adalah sebuah metode untuk melakukan klasifikasi tehadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. KNN termasuk algoritm <em>supervised learning</em> dimana hasil dari <em>query instance</em> yang baru diklasifikasikan berdasarkan mayoritas dari kategori pada KNN. Nanti kelas yang paling banyak muncullah yang akan menjadi kelas hasil klasifikasi. </p>
<p>​            Tujuan dari algoritma ini adalah mengklasifikasikan objek baru berdasarkan atribut dan <em>training sample. Classifier</em> tidak menggunakan model apapun untuk dicocokkan dan hanya berdasarkan pada memori. Diberikan titik <em>query</em>, akan ditemukan sejumlah <em>k</em> obyek atau (titik training) yang paling dekat dengan titik <em>query.</em> Klasifikasi menggunakan voting terbanyak diantara klasifikasi dari k objek. Algoritma k-nearest neighbor (KNN) menggunakan klasifikasi ketetanggaan sebagai nilai prediksi dari query instance yang baru.</p>
<p>Algoritma KNN sangat sederhana, bekerja berdasarkan jarak terpendek dari query intance ke trining sample untuk menentukan KNN-nya. Training sample diproyeksikan ke ruang berdimensi banyak, dimana masing-masing dimensi merepresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi training sample. Sebuah titik pada ruang ini ditandai kelas c, juka kelas c merupakn klasiifikasi yang paling banyak ditemui pada k buah tetangga terdekat dari titik tersebut. Dekat atau jauhnya tetangga biasaya dihitung berdasarkan <em>Euclidien Distance.</em> </p>
<p>​            Jarak Euclidien Distance paling sering digunakan untuk menghitung jarak. Jarak euclidien berfungsi menguji ukuran yang bisa digunakan sebagai interpretasi kedekatan jarak antara dua obyek, yang direpresentasikan adalah sebagai berikut :</p>
<p><img alt="Matrial for Mkdocs" src="assets/images/Rumus Jarak eqluidian.PNG" /></p>
<p>Dimana matriks D(a,b) adalah jarak skalar dari kedua vektor a dan b dari matriks dengan ukuran d dimensi.</p>
<p>​            Semakin besar nilai D akan semakin jauh tingkat kesamaan antara kedua individu dan sebaliknya jika nilai D semakin kecil maka akan semakin dekat tingkat keserupaan antara individu tersebut.</p>
<p>​            Nilai k yang terbaik untuk algoritma ini tergantung pada dat. Secara umum, nilai k yang tinggi akan mengurangi efek noise pada klasifikasi, tetapi membuat batasan antara setiap klasifikasi menjadi semakin kabur. Nilai k yang bagus dapat dipilih dengan optimasi parameter, misal dengan menggunakan cross-validation.</p>
<p>​            Ketepatan algoritma KNN sangat dipengaruhi oleh ada atau tidaknya fitur-fitur yang tidak relevan atau jika bobot fitur tersebut tidak setara dengan relevansinya terhadap klasifikasi. Riset terhadap algoritma ini sebagian besar membahas bagaimana memilih dan memberi dan bobot terhadap fitur agar performa relevansinya terhadap klasifikasi.</p>
<ul>
<li>
<h3 id="langkah-langkah-untuk-menghitung-metode-k-nearest-neighbor"><strong>Langkah-langkah untuk menghitung metode K-Nearest Neighbor :</strong><a class="headerlink" href="#langkah-langkah-untuk-menghitung-metode-k-nearest-neighbor" title="Permanent link">&para;</a></h3>
</li>
</ul>
<p>1.Menentukan parameter k (jumlah tetangga paling dekat)</p>
<p>2.Menghitung kuadrat jarakk euclid(query instance) masing-masing objek terhadap data sampel yang diberikan.</p>
<p>3.Kemudian mengurutkan onjek-objek tersebut kedalam kelompok yang mempunyai jarak euclid terkecil.</p>
<p>4.Mengumpulkan kategori</p>
<p>5.Dengan menggunakan kategori nearest neighbor yang paling mayoritas maka dapat diprediksikan nilai query instance yang telah dihitung.</p>
<ul>
<li><strong>Implementasi</strong></li>
</ul>
<p><strong>Implementasi Menggunakan EXCEL</strong></p>
<p>Terdapat  data yang berasal dari datasets tentang klasifikasi bunga (iris) dengan ciri-ciri yang sudah dituliskan pada ke empat kolom, yaitu kolom sepallenght, sepalwidth, petallenght, dan sepalwidth . </p>
<p><strong>Tabel 1.1 klasifikasi data</strong></p>
<p><img alt="Material for Mkdocs" src="assets/images/1.Data asli (KNN).PNG" /></p>
<p>Kemudian akan dikelompokkan kembali bunga dengan data testing, data testing sebanyak 15 data.</p>
<p><strong>Tabel 2.Data testing</strong></p>
<p><img alt="Material for Mkdocs" src="assets/images/Tabel 1.2 (data testing).PNG" /></p>
<p>Kemudian akan diambil satu baris dari data testing tersebut, misal pada baris pertama dengan nilai sepallenght = 5,1 sepalwidth=3,5 petallenght=1,4 dan sepalwidth=0,2 untuk dapat mengklasifikasikan bunga tersebut termasuk dalam kelas iris-setosa, iris-virginica atau iris-versicolor. </p>
<p>Adapun prosedur k-nearest neighbor adalah sebagai berikut :</p>
<p>1.Menentukan parameter K (Jumlah tetangga paling dekat), misalkan kita menggunakan K=1 sampai K=5</p>
<p>2.Menghitung kuadrat jarak euclid (query-instance) masing-masing objek terhadap contoh data yang diberikan.</p>
<p>Koordinat query -instance adalah ((5,1), (3,5), (1,4), (0,2)) dimana nilai tersebut berasal dari nilai atribut yang akan diproduksi.</p>
<p><strong>Tabel 1.3 perhitungan jarak euclid</strong></p>
<p><img alt="Material for Mkdocs" src="assets/images/8.Langkah 2 (menghitung jarak).PNG" /></p>
<p>Rumus yang diimplementasikan ke dalam excel</p>
<p><img alt="Material for Mkdocs" src="assets/images/Rumus jarak 1.PNG" /></p>
<p>Lambang $ pada rumus tersebut berfungsi untuk mengunci rumus pada suatu cell secara mutlak (baik baris maupun kolom)</p>
<p>3.Kemudian urutkan jarak ecluid tersebut dari jarak terkecil ke terbesar dengan cara pilih <strong>Data –</strong> <strong>Filter – Klik sort smallest to largest</strong></p>
<p><strong>Tabel 1.4 Perhitungan jarak ecluid terkecil</strong></p>
<p><img alt="Material for mkdocs" src="assets/images/jarak yang sudah di urutkan.PNG" /></p>
<p>4.Mengumpulkan bunga kedalam kelasnya masing-masing</p>
<p><strong>Tabel 1.5 Hasil klasifikasi</strong></p>
<p><img alt="Material for Mkdocs" src="assets/images/hasil.png" /></p>
<p>Dengan menggunakan data nearest neighbor yang paling besar (maksimal) nilainya, maka
  dapat diprediksi nilai query instance yang telah dihitung. Berdasarkan hasil diatas maka data pertama masuk kelas iris-setosa</p>
<p><strong>Implementasi KNN menggunakan Python (Program)</strong></p>
<p>Setelah memahami tahap-tahap perhitungan KNN dalam excel, selanjutnya kita melakukan perhitungan dengan menggunakan bahasa pemrogaman python. Agar program ini dapat berjalan maka harus ada library didalam python tersebut. Library yang harus ada antara lain pandas, dan scikit-learn. Kedua library tersebut dapat di install melalui command prompt.</p>
<p><strong>Langkah 1. install pandan dan scikit learn</strong></p>
<p>Berikut cara untuk menginstall pandas dan scikit learn pada command prompt :</p>
<pre class="codehilite"><code>pip install pandas</code></pre>

<pre class="codehilite"><code>pip install scikit-learn</code></pre>

<p>Pandas berfungsi untuk memanggil data dari dataset tersebut</p>
<p>Scikit-learn berfungsi untuk memanggil rumus yang digunakan untuk menentukan neighbod (K)</p>
<p>Langkah-Langkah yang ada dalam program ini sedikit berbeda dengan langkah-langkah yang ada pada excel. Jika dalam excel hasil klasifikasi langsung muncul saat rumus dimasukkan, berbeda dengan program pada phyton, dalam program ini kita harus menginputkan data baru untuk bisa melihat hasil dari program tersebut.</p>
<p><strong>Langkah 2. Tulis kode program pada lembar kerja python</strong></p>
<p>Berikut adalah source code dari program :</p>
<p><strong>[SOURCE CODE]</strong></p>
<pre class="codehilite"><code>import pandas as pd 
from sklearn.neighbors import KNeighborsClassifier
from sklearn import model_selection
from sklearn.model_selection import train_test_split

#memuat file csv
df=pd.read_csv('Iris.csv')



#Inisialisasi KNN
clf=KNeighborsClassifier(n_neighbors=3)



# Dataset validasi dataset
array = df.values
X = array[:,1:5]
Y = array[:,5]

# Sepertiga data sebagai bagian dari set tes
validation_size = 15

seed = 7
X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=seed)

#Menyesuaikan set training
clf.fit(X_train, Y_train) 

#Predicting untuk Set Tes
pred_clf = clf.predict(X_validation)


#Buat file prediksi dengan gabungan data asli dan prediksi
#Membentuk kembali diperlukan untuk melakukan penggabungan
pred_clf_df = pd.DataFrame(pred_clf.reshape(15,1))

#Ganti nama kolom untuk menunjukkan prediksi
pred_clf_df.rename(columns={0:'Prediction'}, inplace=True)

#membentuk kembali dataset uji
X_validation_df = pd.DataFrame(X_validation.reshape(15 ,4))

#menggabungkan dua bingkai data panda di atas kolom untuk membuat dataset prediksi
pred_outcome = pd.concat([X_validation_df, pred_clf_df], axis=1, join_axes=[X_validation_df.index])

pred_outcome.rename(columns = {0:'SepalLengthCm', 1:'SepalWidthCm', 2:'PetalLengthCm', 3:'PetalWidthCm'}, inplace=True)

del df['Id']

#menggabungkan prediksi dengan dataset asli
pred_comp = pd.merge(df,pred_outcome, on=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'])

#cetak 10 baris prediksi akhir
print((pred_comp).head(15))
print ("\n")

# make prediction
sl = float(input('Enter sepal length (cm): '))
sw = float(input('Enter sepal width (cm): '))
tl = float(input('Enter tepal length (cm): '))
tw = float(input('Enter tepal width (cm): '))
dataClass = clf.predict([[sl,sw,tl,tw]])
print ("\n")
print('Prediction: ', dataClass)
print ("\n")
</code></pre>

<p><strong>Langkah 3.Jalankan program (run) program, dan hasil program nya adalah sebagai berikut</strong></p>
<pre class="codehilite"><code>   SepalLengthCm SepalWidthCm  ...          Species       Prediction
0            4.8          3.4  ...      Iris-setosa      Iris-setosa
1            5.2          3.4  ...      Iris-setosa      Iris-setosa
2            5.2          4.1  ...      Iris-setosa      Iris-setosa
3              5          3.5  ...      Iris-setosa      Iris-setosa
4            4.5          2.3  ...      Iris-setosa      Iris-setosa
5            6.4          3.2  ...  Iris-versicolor  Iris-versicolor
6            6.9          3.1  ...  Iris-versicolor  Iris-versicolor
7            5.6            3  ...  Iris-versicolor  Iris-versicolor
8            6.7            3  ...  Iris-versicolor  Iris-versicolor
9            5.4            3  ...  Iris-versicolor  Iris-versicolor
10             6          3.4  ...  Iris-versicolor  Iris-versicolor
11           5.6          2.7  ...  Iris-versicolor  Iris-versicolor
12           4.9          2.5  ...   Iris-virginica  Iris-versicolor
13           7.2          3.6  ...   Iris-virginica   Iris-virginica
14           5.9            3  ...   Iris-virginica   Iris-virginica

[15 rows x 6 columns</code></pre>

<p><strong>Langkah 4.Inputkan data baru yang akan diklasifikasikan</strong></p>
<pre class="codehilite"><code>Enter sepal length (cm): 3
Enter sepal width (cm): 4.5
Enter petal length (cm): 5
Enter petal width (cm): 4
</code></pre>

<p><strong>Hasil inputan</strong></p>
<pre class="codehilite"><code>Prediction:  ['Iris-virginica']</code></pre>

<p>Hasil dari inputan sepallength (3), sepalwidth (4.5), petallenght (5), petalwidth (4) adalah <strong>iris virginica</strong>.</p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
        
          <a href="tree/" title="Decision Tree" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Decision Tree
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2016 - 2019 RizkaRamadhani
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="assets/fonts/font-awesome.css">
    
      <a href="https://webrizka.000webhostapp.com/" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/RizkaRamadhani" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://instagram.com/RizkaRamadhani" class="md-footer-social__link fa fa-instagram"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:"."}})</script>
      
    
  </body>
</html>